{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c1e57d-3cdb-43d4-a48b-4021e8f8311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no stats provided, assuming will be loaded later, initializing randomly\n",
      "unkown kwargs ['dataset_params', 'ckpt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1552"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../gaia-surrogate\")\n",
    "import torch\n",
    "from gaia.models import TrainingModel\n",
    "from gaia.training import get_checkpoint_file\n",
    "model_dir = \"/proj/gaia-climate/team/kirill/gaia-surrogate/lightning_logs_hparam/version_0\"\n",
    "model = TrainingModel.load_from_checkpoint(\n",
    "            get_checkpoint_file(model_dir), map_location = \"cpu\",\n",
    "        )\n",
    "_ = model.eval()\n",
    "example = torch.rand(10,164)\n",
    "out = model.model(example)\n",
    "traced_script_module = torch.jit.trace(model.model, example)\n",
    "traced_script_module.save(\"traced_model.pt\")\n",
    "from collections import \n",
    "open(\"traced_model_arch_printed.txt\",\"w\").write(str(traced_script_module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8651ed4d-8f1f-47b7-999e-803d5393e89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingModel(\n",
       "  (input_normalize): Normalization()\n",
       "  (output_normalize): Normalization()\n",
       "  (model): FcnBaseline(\n",
       "    (model): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=164, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.01, inplace=False)\n",
       "        (3): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.01, inplace=False)\n",
       "        (3): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.01, inplace=False)\n",
       "        (3): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.01, inplace=False)\n",
       "        (3): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.01, inplace=False)\n",
       "        (3): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.01, inplace=False)\n",
       "        (3): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (6): Linear(in_features=512, out_features=54, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "550c188c-9702-45df-9c53-04f71814c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70208d07-c5ce-4ed2-8398-6297f5d2df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = list(model.hparams.input_index.keys())\n",
    "outputs = list(model.hparams.output_index.keys())\n",
    "\n",
    "np.random.shuffle(inputs)\n",
    "np.random.shuffle(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3940d76-a717-405a-b00d-6320c32069ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FLNT',\n",
       " 'FLNS',\n",
       " 'T',\n",
       " 'SOLIN',\n",
       " 'Z3',\n",
       " 'OMEGA',\n",
       " 'FSNS',\n",
       " 'LHFLX',\n",
       " 'FSNT',\n",
       " 'SHFLX',\n",
       " 'U',\n",
       " 'V',\n",
       " 'Q',\n",
       " 'PSL']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b474ad8c-c3c8-48ff-a512-3e9221c3207a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1837"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModelForExport(torch.nn.Module):\n",
    "    def __init__(self, training_model, input_order, output_order):\n",
    "        super().__init__()\n",
    "        self.input_normalize = training_model.input_normalize\n",
    "        self.output_normalize = training_model.output_normalize\n",
    "        self.model = training_model.model\n",
    "        \n",
    "        \n",
    "        input_order_index = OrderedDict()\n",
    "        i = 0\n",
    "        \n",
    "        for k in input_order:\n",
    "            s,e  = training_model.hparams.input_index[k]\n",
    "            v_size = e - s\n",
    "            input_order_index[k] = (i,i + v_size)\n",
    "            i = i + v_size\n",
    "\n",
    "        self.register_buffer(\"input_order\",torch.cat([torch.arange(*input_order_index[k]) for k in training_model.hparams.input_index.keys()]))\n",
    "        self.register_buffer(\"output_order\",torch.cat([torch.arange(*training_model.hparams.output_index[k]) for k in output_order]))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x[:,self.input_order,...]\n",
    "        x = self.input_normalize(x)\n",
    "        \n",
    "        y = self.model(x)\n",
    "        y = self.output_normalize(y, normalize=False)\n",
    "        y = y[:,self.output_order,...]\n",
    "        return y\n",
    "    \n",
    "    \n",
    "model_for_export = ModelForExport(model, inputs, outputs).eval()\n",
    "example = torch.rand(10,164)\n",
    "out = model_for_export(example)\n",
    "traced_script_module = torch.jit.trace(model_for_export, example)\n",
    "traced_script_module.save(\"traced_model.pt\")\n",
    "\n",
    "open(\"traced_model_arch_printed.txt\",\"w\").write(str(traced_script_module))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praxis",
   "language": "python",
   "name": "praxis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
